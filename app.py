import streamlit as st
from duckduckgo_search import DDGS
from docx import Document
from io import BytesIO
from datetime import datetime

st.set_page_config(page_title="Corporation-Scope", layout="wide")
st.title("Corporation-Scope: Strategic Intelligence")

st.caption("å†ç”ŸåŒ»ç™‚ãƒ»ãƒã‚¤ã‚ªæ¥­ç•Œç‰¹åŒ–ï¼šæœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨ä¸Šå ´çŠ¶æ³ã‚’ãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã«æŠ½å‡ºã—ã¾ã™ã€‚")

target_input = st.text_input("Target Entity", placeholder="Enter name (e.g. ã‚»ãƒ«ãƒªã‚½ãƒ¼ã‚·ã‚º, Cellares)...")

if st.button("EXECUTE"):
    if not target_input:
        st.warning("Please enter a name.")
    else:
        with st.spinner(f"Analyzing '{target_input}'..."):
            
            # 1. ä¸Šå ´åˆ¤å®š
            is_public = False
            public_keywords = ["sony", "ã‚½ãƒ‹ãƒ¼", "ãƒˆãƒ¨ã‚¿", "toyota", "terumo", "ãƒ†ãƒ«ãƒ¢"]
            if any(k in target_input.lower() for k in public_keywords):
                is_public = True
            else:
                try:
                    with DDGS() as ddgs:
                        s_res = list(ddgs.text(f"{target_input} æ ªä¾¡ éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ è¨¼åˆ¸", max_results=5))
                        for s in s_res:
                            if any(k in s['href'].lower() for k in ["finance.yahoo", "kabutan", "nikkei.com", "shikiho.jp"]):
                                if "ã‚»ãƒ«ãƒªã‚½ãƒ¼ã‚·ã‚º" in target_input: continue # è‡ªç¤¾ã¯éä¸Šå ´
                                is_public = True
                                break
                except: pass

           # 2. ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢ï¼ˆã€Œå‡ºãªã„ã€ã‚’å›é¿ã™ã‚‹4æ®µéšã‚¹ã‚­ãƒ£ãƒ³ï¼‰
            news_results = []
            try:
                with DDGS() as ddgs:
                    # ã‚¹ãƒ†ãƒƒãƒ—1ï¼šæœ€æ–°ã®æ¥­ç•Œãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆé«˜ç²¾åº¦ï¼‰
                    q1 = f'"{target_input}" å†ç”ŸåŒ»ç™‚' if not target_input.isascii() else f'"{target_input}" "cell therapy"'
                    news_results = list(ddgs.news(q1, max_results=10))
                    
                    # ã‚¹ãƒ†ãƒƒãƒ—2ï¼šå°‘ãªã‘ã‚Œã°ã€Œç¤¾åã®ã¿ã€ã§æ¤œç´¢
                    if len(news_results) < 3:
                        q2 = f'"{target_input}"'
                        more_news = list(ddgs.news(q2, max_results=10))
                        existing_urls = {n['url'] for n in news_results}
                        for n in more_news:
                            if n['url'] not in existing_urls:
                                news_results.append(n)
                    
                    # ã‚¹ãƒ†ãƒƒãƒ—3ï¼šãƒ‹ãƒ¥ãƒ¼ã‚¹æ ã«ç„¡ã‘ã‚Œã°é€šå¸¸ã®Webæ¤œç´¢ï¼ˆPR TIMESç­‰ã‚’æ‹¾ã†ï¼‰
                    if len(news_results) < 2:
                        web_news = list(ddgs.text(f"{target_input} ãƒ‹ãƒ¥ãƒ¼ã‚¹ news", max_results=5))
                        for w in web_news:
                            news_results.append({
                                'title': w['title'],
                                'source': 'Web info',
                                'date': 'Recent',
                                'body': w['body'],
                                'url': w['href']
                            })
                    
                    # ã‚¹ãƒ†ãƒƒãƒ—4ï¼šãã‚Œã§ã‚‚ã‚¼ãƒ­ãªã‚‰ã€Œé–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€ã§æ¤œç´¢ï¼ˆæœ€çµ‚æ‰‹æ®µï¼‰
                    if not news_results and not target_input.isascii():
                        news_results = list(ddgs.news("å†ç”ŸåŒ»ç™‚ ç´°èƒæ²»ç™‚ æœ€æ–°", max_results=5))
            except Exception:
                pass

            st.divider()
            
            col1, col2 = st.columns([1, 2])
            
            with col1:
                st.subheader("ğŸ“Š Market Status")
                if is_public:
                    st.success("### **Publicly Traded**\n(ä¸Šå ´ä¼æ¥­/ã‚°ãƒ«ãƒ¼ãƒ—å‚˜ä¸‹)")
                else:
                    st.info("### **Private / Unlisted**\n(éä¸Šå ´ / ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—)")
                st.caption("â€» å…¬é–‹æƒ…å ±ã«åŸºã¥ã„ãŸè‡ªå‹•åˆ¤å®šã§ã™ã€‚")

            with col2:
                st.subheader("ğŸ“¡ Intelligence Feed")
                if not news_results:
                    st.warning("ç›´è¿‘ã®é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                else:
                    # ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ–°ã—ã„é †ã«è¡¨ç¤º
                    for item in news_results:
                        with st.expander(f"{item['title']}", expanded=True):
                            st.write(f"**Source:** {item['source']} | **Date:** {item['date']}")
                            st.write(item['body'])
                            st.markdown(f"[è¨˜äº‹å…¨æ–‡ã‚’èª­ã‚€]({item['url']})")

            # Wordãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
            doc = Document()
            doc.add_heading(f'Strategic Report: {target_input}', 0)
            doc.add_paragraph(f"Report Date: {datetime.now().strftime('%Y-%m-%d')}")
            doc.add_heading('Market Status', level=1)
            doc.add_paragraph("Publicly Traded" if is_public else "Private / Unlisted")
            doc.add_heading('Latest News', level=1)
            for n in news_results[:10]:
                doc.add_heading(n['title'], level=2)
                doc.add_paragraph(f"Source: {n['source']} | Date: {n['date']}")
                doc.add_paragraph(n['body'])
                doc.add_paragraph(f"URL: {n['url']}")

            bio = BytesIO()
            doc.save(bio)
            st.download_button(label="ğŸ’¾ Download Summary Report", data=bio.getvalue(), file_name=f"{target_input}_Report.docx")



