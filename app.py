import streamlit as st
import requests
from docx import Document
from io import BytesIO
from datetime import datetime

# --- ã€æœ€é‡è¦ã€‘ã“ã“ã«å–å¾—ã—ãŸã€Œéµã€ã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„ ---
GOOGLE_API_KEY = "AIzaSyAk2sfv67SGkZ4gAiKPLdSPgSWIAYYO0zo"
GOOGLE_CX = "<script async src="https://cse.google.com/cse.js?cx=43b6a568b52e34409">
</script>
<div class="gcse-search"></div>"

st.set_page_config(page_title="Corporation-Scope Pro", layout="wide")
st.title("Corporation-Scope: Strategic Intelligence")
st.caption("Google Search API æ­è¼‰ï¼šã‚¢ã‚¯ã‚»ã‚¹åˆ¶é™ãªã—ã®æ¥­ç•Œç‰¹åŒ–ã‚¹ã‚­ãƒ£ãƒŠãƒ¼ã€‚")

target_input = st.text_input("Target Entity", placeholder="Enter name (e.g. ã‚»ãƒ«ãƒªã‚½ãƒ¼ã‚·ã‚º, ENCell, Cellares)...")

if st.button("EXECUTE"):
    if not target_input:
        st.warning("Please enter a name.")
    else:
        with st.spinner(f"Querying Google Intelligence for '{target_input}'..."):
            
            news_results = []
            
            try:
                # æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰ã®èª¿æ•´ï¼ˆãƒ’ãƒƒãƒˆç‡ã‚’é«˜ã‚ã‚‹ãŸã‚ã«ãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å¤–ã—ã¾ã—ãŸï¼‰
                if target_input.isascii():
                    query = f'{target_input} "cell therapy" news'
                else:
                    query = f'{target_input} å†ç”ŸåŒ»ç™‚ ãƒ‹ãƒ¥ãƒ¼ã‚¹ 2025'
                
                url = f"https://www.googleapis.com/customsearch/v1?key={GOOGLE_API_KEY}&cx={GOOGLE_CX}&q={query}"
                
                response = requests.get(url)
                data = response.json()
                
                # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
                if "error" in data:
                    st.error(f"Google API Error: {data['error']['message']}")
                elif "items" in data:
                    for item in data["items"]:
                        news_results.append({
                            'title': item.get('title'),
                            'source': item.get('displayLink'),
                            'date': 'Recent',
                            'body': item.get('snippet'),
                            'url': item.get('link')
                        })
                
                # 1ä»¶ã‚‚å‡ºãªã„å ´åˆã®ãƒªãƒˆãƒ©ã‚¤ï¼ˆç¤¾åã®ã¿ã§æ¤œç´¢ï¼‰
                if not news_results and "error" not in data:
                    url_retry = f"https://www.googleapis.com/customsearch/v1?key={GOOGLE_API_KEY}&cx={GOOGLE_CX}&q={target_input}"
                    resp_retry = requests.get(url_retry)
                    data_retry = resp_retry.json()
                    if "items" in data_retry:
                        for item in data_retry["items"]:
                            news_results.append({
                                'title': item.get('title'),
                                'source': item.get('displayLink'),
                                'date': 'General Info',
                                'body': item.get('snippet'),
                                'url': item.get('link')
                            })

            except Exception as e:
                st.error(f"Connection Error: {e}")

            st.divider()
            
            # --- ç”»é¢è¡¨ç¤º ---
            if not news_results:
                st.warning("é–¢é€£æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚è¨­å®šã‚’ç¢ºèªã™ã‚‹ã‹ã€åˆ¥ã®ç¤¾åã‚’ãŠè©¦ã—ãã ã•ã„ã€‚")
            else:
                st.subheader(f"ğŸ“¡ Real-time Intelligence: {target_input}")
                cols = st.columns(2)
                for idx, item in enumerate(news_results[:12]):
                    with cols[idx % 2].expander(f"{item['title']}", expanded=True):
                        st.caption(f"ğŸ¢ Source: {item['source']}")
                        st.write(item['body'])
                        st.markdown(f"[è¨˜äº‹å…¨æ–‡ã‚’èª­ã‚€]({item['url']})")

            # --- Wordãƒ¬ãƒãƒ¼ãƒˆä½œæˆ ---
            doc = Document()
            doc.add_heading(f'Strategic Report: {target_input}', 0)
            doc.add_paragraph(f"Generated: {datetime.now().strftime('%Y-%m-%d')}")
            for n in news_results[:10]:
                doc.add_heading(n['title'], level=2)
                doc.add_paragraph(n['body'])
                doc.add_paragraph(f"URL: {n['url']}")
            
            bio = BytesIO()
            doc.save(bio)
            st.download_button(label="ğŸ’¾ Download Summary Report", data=bio.getvalue(), file_name=f"{target_input}_Report.docx")








