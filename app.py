import streamlit as st
from duckduckgo_search import DDGS
from docx import Document
from io import BytesIO
from datetime import datetime
import time
import random

st.set_page_config(page_title="Corporation-Scope", layout="wide")
st.title("Corporation-Scope: Strategic Intelligence")
st.caption("å†ç”ŸåŒ»ç™‚ãƒ»ãƒã‚¤ã‚ªæ¥­ç•Œç‰¹åŒ–ï¼šæœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨ä¸Šå ´çŠ¶æ³ã‚’ãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã«æŠ½å‡ºã—ã¾ã™ã€‚")

target_input = st.text_input("Target Entity", placeholder="Enter name (e.g. ã‚»ãƒ«ãƒªã‚½ãƒ¼ã‚·ã‚º, Cellares)...")

if st.button("EXECUTE"):
    if not target_input:
        st.warning("Please enter a name.")
    else:
        with st.spinner(f"Analyzing '{target_input}'..."):
            
          # 1. ä¸Šå ´åˆ¤å®šï¼ˆã‚°ãƒ­ãƒ¼ãƒãƒ«å¸‚å ´å¯¾å¿œç‰ˆï¼‰
            is_public = False
            # æ˜ã‚‰ã‹ãªä¸Šå ´ä¼æ¥­ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
            public_keywords = ["sony", "ã‚½ãƒ‹ãƒ¼", "ãƒˆãƒ¨ã‚¿", "toyota", "terumo", "ãƒ†ãƒ«ãƒ¢", "encell"]
            
            if any(k in target_input.lower() for k in public_keywords):
                is_public = True
            else:
                try:
                    with DDGS() as ddgs:
                        # è‹±èªåœã®è¨¼åˆ¸ç”¨èªã€ŒStock Priceã€ã€ŒTickerã€ã‚’æ··ãœã¦æ¤œç´¢
                        s_res = list(ddgs.text(f"{target_input} stock price ticker éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰", max_results=8))
                        for s in s_res:
                            # åˆ¤å®šç”¨ãƒ‰ãƒ¡ã‚¤ãƒ³ã«æµ·å¤–å‹¢ï¼ˆInvesting.com, Reuters, Bloombergç­‰ï¼‰ã‚’è¿½åŠ 
                            if any(k in s['href'].lower() for k in [
                                "finance.yahoo", "kabutan", "nikkei.com", "shikiho.jp", 
                                "investing.com", "reuters.com", "bloomberg.com", "marketwatch"
                            ]):
                                # ã‚»ãƒ«ãƒªã‚½ãƒ¼ã‚·ã‚ºè‡ªä½“ã®éä¸Šå ´åˆ¤å®šã¯ç¶­æŒ
                                if "ã‚»ãƒ«ãƒªã‚½ãƒ¼ã‚·ã‚º" in target_input: continue 
                                is_public = True
                                break
                except: pass

            # 2. ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢ï¼ˆã‚¢ã‚¯ã‚»ã‚¹åˆ¶é™å›é¿ & å¿…ä¸­ä»•æ§˜ï¼‰
            news_results = []
            try:
                # æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‚’é£½ãã•ã›ãªã„ãŸã‚ã®ã€Œæºã‚‰ãã€
                suffix = random.choice(["ãƒ‹ãƒ¥ãƒ¼ã‚¹", "æœ€æ–°", "å‹•å‘", "news"])
                lang_query = "cell therapy" if target_input.isascii() else f"å†ç”ŸåŒ»ç™‚ {suffix}"
                
                with DDGS() as ddgs:
                    # æ¤œç´¢å‰ã«å°‘ã—å¾…æ©Ÿã—ã¦ãƒ–ãƒ­ãƒƒã‚¯ã‚’é˜²ã
                    time.sleep(random.uniform(0.5, 1.0))
                    
                    # æ¤œç´¢
                    news_results = list(ddgs.news(f'"{target_input}" {lang_query}', max_results=8))
                    
                    # ãƒ’ãƒƒãƒˆãŒå°‘ãªã‘ã‚Œã°ã€æ¡ä»¶ã‚’ç·©ã‚ã¦å†æ¤œç´¢
                    if len(news_results) < 3:
                        time.sleep(0.5)
                        more_news = list(ddgs.news(f'"{target_input}"', max_results=8))
                        existing_urls = {n['url'] for n in news_results}
                        for n in more_news:
                            if n['url'] not in existing_urls:
                                news_results.append(n)
            except Exception:
                st.error("æ¤œç´¢åˆ¶é™ãŒã‹ã‹ã‚Šã¾ã—ãŸã€‚å°‘ã—æ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")

            st.divider()
            
            # --- ç”»é¢è¡¨ç¤º ---
            col1, col2 = st.columns([1, 2])
            
            with col1:
                st.subheader("ğŸ“Š Market Status")
                if is_public:
                    st.success("### **Publicly Traded**\n(ä¸Šå ´ä¼æ¥­/ã‚°ãƒ«ãƒ¼ãƒ—å‚˜ä¸‹)")
                else:
                    st.info("### **Private / Unlisted**\n(éä¸Šå ´ / ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—)")
                st.markdown("---")
                st.caption("â€» å…¬é–‹æƒ…å ±ã«åŸºã¥ã„ãŸåˆ¤å®šã§ã™ã€‚")

            with col2:
                st.subheader("ğŸ“¡ Intelligence Feed")
                if not news_results:
                    st.warning("ç›´è¿‘ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                else:
                    for item in news_results:
                        with st.expander(f"{item['title']}", expanded=True):
                            st.write(f"**Source:** {item['source']} | **Date:** {item['date']}")
                            st.write(item['body'])
                            st.markdown(f"[è¨˜äº‹å…¨æ–‡ã‚’èª­ã‚€]({item['url']})")

            # --- Wordå‡ºåŠ›ï¼ˆå ±å‘Šæ›¸ä½œæˆï¼‰ ---
            doc = Document()
            doc.add_heading(f'Strategic Report: {target_input}', 0)
            doc.add_paragraph(f"Generated on: {datetime.now().strftime('%Y-%m-%d')}")
            doc.add_heading('Market Status', level=1)
            doc.add_paragraph("Publicly Traded" if is_public else "Private / Unlisted")
            doc.add_heading('Latest News', level=1)
            for n in news_results[:10]:
                doc.add_heading(n['title'], level=2)
                doc.add_paragraph(f"Source: {n['source']} | Date: {n['date']}")
                doc.add_paragraph(n['body'])
                doc.add_paragraph(f"URL: {n['url']}")

            bio = BytesIO()
            doc.save(bio)
            st.download_button(label="ğŸ’¾ Download Summary Report", data=bio.getvalue(), file_name=f"{target_input}_Report.docx")





