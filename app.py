import streamlit as st
from duckduckgo_search import DDGS
from docx import Document
from io import BytesIO
from datetime import datetime

st.set_page_config(page_title="Corporation-Scope", layout="wide")
st.title("Corporation-Scope: Strategic Intelligence")

st.caption("å†ç”ŸåŒ»ç™‚ãƒ»ãƒã‚¤ã‚ªæ¥­ç•Œç‰¹åŒ–ï¼šæœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨ä¸Šå ´çŠ¶æ³ã‚’ãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã«æŠ½å‡ºã—ã¾ã™ã€‚")

target_input = st.text_input("Target Entity", placeholder="Enter name (e.g. ã‚»ãƒ«ãƒªã‚½ãƒ¼ã‚·ã‚º, Cellares)...")

if st.button("EXECUTE"):
    if not target_input:
        st.warning("Please enter a name.")
    else:
        with st.spinner(f"Analyzing '{target_input}'..."):
            
            # 1. ä¸Šå ´åˆ¤å®š
            is_public = False
            public_keywords = ["sony", "ã‚½ãƒ‹ãƒ¼", "ãƒˆãƒ¨ã‚¿", "toyota", "terumo", "ãƒ†ãƒ«ãƒ¢"]
            if any(k in target_input.lower() for k in public_keywords):
                is_public = True
            else:
                try:
                    with DDGS() as ddgs:
                        s_res = list(ddgs.text(f"{target_input} æ ªä¾¡ éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ è¨¼åˆ¸", max_results=5))
                        for s in s_res:
                            if any(k in s['href'].lower() for k in ["finance.yahoo", "kabutan", "nikkei.com", "shikiho.jp"]):
                                if "ã‚»ãƒ«ãƒªã‚½ãƒ¼ã‚·ã‚º" in target_input: continue # è‡ªç¤¾ã¯éä¸Šå ´
                                is_public = True
                                break
                except: pass

            # 2. ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢ï¼ˆæ®µéšçš„æ¤œç´¢ã§ãƒ’ãƒƒãƒˆç‡ã‚’æœ€å¤§åŒ–ï¼‰
            news_results = []
            try:
                with DDGS() as ddgs:
                    # ã‚¹ãƒ†ãƒƒãƒ—1ï¼šæ¥­ç•Œã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä»˜ã‘ã¦æ¤œç´¢
                    lang_query = "cell therapy" if target_input.isascii() else "å†ç”ŸåŒ»ç™‚"
                    news_results = list(ddgs.news(f'"{target_input}" {lang_query}', max_results=10))
                    
                    # ã‚¹ãƒ†ãƒƒãƒ—2ï¼šå°‘ãªã‘ã‚Œã°ç¤¾åã®ã¿ã§æ¤œç´¢
                    if len(news_results) < 3:
                        existing_urls = {n['url'] for n in news_results}
                        for n in list(ddgs.news(f'"{target_input}"', max_results=10)):
                            if n['url'] not in existing_urls:
                                news_results.append(n)
            except: pass

            st.divider()
            
            col1, col2 = st.columns([1, 2])
            
            with col1:
                st.subheader("ğŸ“Š Market Status")
                if is_public:
                    st.success("### **Publicly Traded**\n(ä¸Šå ´ä¼æ¥­/ã‚°ãƒ«ãƒ¼ãƒ—å‚˜ä¸‹)")
                else:
                    st.info("### **Private / Unlisted**\n(éä¸Šå ´ / ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—)")
                st.caption("â€» å…¬é–‹æƒ…å ±ã«åŸºã¥ã„ãŸè‡ªå‹•åˆ¤å®šã§ã™ã€‚")

            with col2:
                st.subheader("ğŸ“¡ Intelligence Feed")
                if not news_results:
                    st.warning("ç›´è¿‘ã®é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                else:
                    # ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ–°ã—ã„é †ã«è¡¨ç¤º
                    for item in news_results:
                        with st.expander(f"{item['title']}", expanded=True):
                            st.write(f"**Source:** {item['source']} | **Date:** {item['date']}")
                            st.write(item['body'])
                            st.markdown(f"[è¨˜äº‹å…¨æ–‡ã‚’èª­ã‚€]({item['url']})")

            # Wordãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
            doc = Document()
            doc.add_heading(f'Strategic Report: {target_input}', 0)
            doc.add_paragraph(f"Report Date: {datetime.now().strftime('%Y-%m-%d')}")
            doc.add_heading('Market Status', level=1)
            doc.add_paragraph("Publicly Traded" if is_public else "Private / Unlisted")
            doc.add_heading('Latest News', level=1)
            for n in news_results[:10]:
                doc.add_heading(n['title'], level=2)
                doc.add_paragraph(f"Source: {n['source']} | Date: {n['date']}")
                doc.add_paragraph(n['body'])
                doc.add_paragraph(f"URL: {n['url']}")

            bio = BytesIO()
            doc.save(bio)
            st.download_button(label="ğŸ’¾ Download Summary Report", data=bio.getvalue(), file_name=f"{target_input}_Report.docx")


